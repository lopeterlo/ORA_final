{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('./data/train.jsonl', lines= True)\n",
    "valid = pd.read_json('./data/valid.jsonl', lines= True)\n",
    "test = pd.read_json('./data/test.jsonl', lines= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'A man and a child have been killed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71604, 5)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 5)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_bounds</th>\n",
       "      <th>extractive_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, summary, text, sent_bounds, extractive_summary]\n",
       "Index: []"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.text.str.contains(data)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_bounds</th>\n",
       "      <th>extractive_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, summary, text, sent_bounds, extractive_summary]\n",
       "Index: []"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid[valid.text.str.contains(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_bounds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, text, sent_bounds]\n",
       "Index: []"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.text.str.contains(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>sent_bounds</th>\n",
       "      <th>extractive_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000</td>\n",
       "      <td>A seven-hundred-year old oak gate at Salisbury...</td>\n",
       "      <td>The Grade I listed Harnham Gate was hit by a w...</td>\n",
       "      <td>[[0, 107], [107, 255], [255, 362]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                            summary  \\\n",
       "0  1000000  A seven-hundred-year old oak gate at Salisbury...   \n",
       "\n",
       "                                                text  \\\n",
       "0  The Grade I listed Harnham Gate was hit by a w...   \n",
       "\n",
       "                          sent_bounds  extractive_summary  \n",
       "0  [[0, 107], [107, 255], [255, 362]]                   1  "
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((71604, 5), (20000, 5))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "class words_dict():\n",
    "    def __init__(self):\n",
    "        self.word_count = collections.defaultdict(int)\n",
    "        self.id_to_word = {0: '_sos_', 1: '_eos_', 2: '_unk_'}\n",
    "        self.word_to_id = {'_sos_': 0, '_eos_': 1, '_unk_': 2}\n",
    "        self.n_words = 3\n",
    "        self.tokenizer =  RegexpTokenizer(r'\\w+')\n",
    "        self.remain_id = []\n",
    "        self.max_len = 200\n",
    "        \n",
    "    def add_word(self, sentence):\n",
    "        tokens = self.tokenizer.tokenize(sentence)\n",
    "        for token in tokens:\n",
    "            token = token.lower()\n",
    "            if self.word_to_id.get(token):\n",
    "                self.word_count[token] += 1\n",
    "            else:\n",
    "                self.word_to_id[token] = self.n_words\n",
    "                self.id_to_word[self.n_words] = token\n",
    "                self.n_words += 1\n",
    "                self.word_count[token] = 1\n",
    "\n",
    "    \n",
    "    def predict(self, sentence):\n",
    "        tokens = self.tokenizer.tokenize(sentence)\n",
    "        t_sen = [0] + (self.max_len - 1) * [1]\n",
    "        for idx, token in enumerate(tokens):\n",
    "            if idx+1 == self.max_len - 1:\n",
    "                t_sen = t_sen[:-1] +  [1]\n",
    "                break\n",
    "            token = token.lower()\n",
    "            if not self.word_to_id.get(token) :\n",
    "                t_sen[idx+1] = 2\n",
    "            else:\n",
    "                t_sen[idx+1] = self.word_to_id[token]\n",
    "        return t_sen\n",
    "    \n",
    "    def sort_dict(self):\n",
    "        sort_d = sorted(self.word_count.items(), key = lambda x: x[1])[:int(self.n_words *0.8)]\n",
    "        for (word, j) in sort_d:\n",
    "            id = self.word_to_id[word]\n",
    "            del self.word_to_id[word]\n",
    "            del self.id_to_word[id]\n",
    "        words = self.word_to_id.keys()\n",
    "        print(f'Word count after reduce: {len(words)}')\n",
    "        word_count = 0\n",
    "        for w in words:\n",
    "            self.id_to_word[word_count] = w\n",
    "            self.word_to_id[w] = word_count \n",
    "            word_count += 1\n",
    "        self.n_word = word_count\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df, name, dic= None):\n",
    "    if not dic:\n",
    "        dictionary = words_dict()\n",
    "        for i in range(len(df)):\n",
    "            text = df.loc[i, 'text']\n",
    "            dictionary.add_word(text)\n",
    "        print(f'Total {len(dictionary.word_to_id)} words')\n",
    "        dictionary.sort_dict()\n",
    "        t_sen, summary = [], []\n",
    "        for i in range(len(df)):\n",
    "            text = df.loc[i, 'text']\n",
    "            ans = df.loc[i, 'summary']\n",
    "            t_sen.append(dictionary.predict(text))\n",
    "            summary.append(dictionary.predict(ans))\n",
    "        t_sen = torch.tensor(t_sen)\n",
    "        summary = torch.tensor(summary)\n",
    "        torch.save(t_sen, f'./data/{name}.trc')\n",
    "        torch.save(summary, f'./data/{name}_summary.trc')\n",
    "        print(f'Total {len(dictionary.word_to_id)} words')\n",
    "        return  dictionary, t_sen, summary\n",
    "    else:\n",
    "        t_sen, summary, id_list = [], [], []\n",
    "        for i in range(len(df)):\n",
    "            text = df.loc[i, 'text']\n",
    "            ans = df.loc[i, 'summary']\n",
    "            id = df.loc[i, 'id']\n",
    "            t_sen.append(dic.predict(text))\n",
    "            summary.append(dic.predict(ans))\n",
    "            id_list.append(id)\n",
    "        t_sen = torch.tensor(t_sen)\n",
    "        summary = torch.tensor(summary)\n",
    "        torch.save(t_sen, f'./data/{name}.trc')\n",
    "        torch.save(summary, f'./data/{name}_summary.trc')\n",
    "        torch.save(id_list, f'./data/{name}_idlist')\n",
    "        print(f'Total {len(dic.word_to_id)} words')\n",
    "        return  t_sen, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 127369 words\n",
      "Word count after reduce: 25474\n",
      "Total 25474 words\n"
     ]
    }
   ],
   "source": [
    "train_dict, t_sen, t_sum = transform(train, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train_dict_cut.pkl', 'wb') as f:\n",
    "    pickle.dump(train_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 25474 words\n"
     ]
    }
   ],
   "source": [
    "v_sen, v_sum = transform(valid, 'valid', train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fonte'"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict.id_to_word[18249]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save glove embedding mapping  id:{emb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "with open(\"./data/glove.6B.300d.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector\n",
    "# add SOS and EOS\n",
    "embeddings_dict['_sos_'] =  np.random.rand(300, )\n",
    "embeddings_dict['_eos_'] =  np.random.rand(300, )\n",
    "embeddings_dict['_unk_'] =  np.random.rand(300, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = words_dict()\n",
    "with open('./data/train_dict_cut.pkl', 'rb') as f:\n",
    "    dictionary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {}\n",
    "for key, val in dictionary.id_to_word.items():\n",
    "    mapping_dict[key] = embeddings_dict.get(val, embeddings_dict['_unk_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/glove_id_to_emb.pkl', 'wb') as f:\n",
    "    pickle.dump(mapping_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 100])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 100\n",
    "a = torch.rand(8,31)\n",
    "batch, length = a.size()\n",
    "lack = max_len - length\n",
    "end = torch.ones(batch, max_len - length)\n",
    "b = torch.cat((a,end), axis = 1)\n",
    "b.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peter",
   "language": "python",
   "name": "peter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
